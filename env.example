# LLM Configuration
LLM_PROVIDER=ollama  # Options: "ollama", "openai", "anthropic", "google"
LLM_MODEL=deepseek-coder:1.3b  # Model name for the selected provider

# Ollama Configuration (for local development)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-coder:1.3b

# API Keys (for production providers)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# Database
DATABASE_URL=postgresql://postgres:password@localhost:5432/vibe_app

# Redis
REDIS_URL=redis://localhost:6379

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000

# Application Settings
DEBUG=false
LOG_LEVEL=INFO
SECRET_KEY=your-secret-key-here

# DSPy Configuration
DSPY_MAX_TOKENS=4000
DSPY_TEMPERATURE=0.1
